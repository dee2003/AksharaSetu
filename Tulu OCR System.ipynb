{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d93778-d804-471d-ac0b-a04637329ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def augment_images_with_slant(input_folder, output_folder, target_size=(150, 150)):\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for idx, file in enumerate(files):\n",
    "            input_path = os.path.join(root, file)\n",
    "            output_subfolder = os.path.relpath(root, input_folder)\n",
    "\n",
    "            # Ensure the output subfolder exists\n",
    "            output_subfolder_path = os.path.join(output_folder, output_subfolder)\n",
    "            os.makedirs(output_subfolder_path, exist_ok=True)\n",
    "\n",
    "            try:\n",
    "                # Read the image\n",
    "                original_image = cv2.imread(input_path)\n",
    "\n",
    "                # Resize the image to the target size\n",
    "                resized_image = cv2.resize(original_image, target_size)\n",
    "\n",
    "                # Convert image to grayscale\n",
    "                gray_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "                # Binarize the image and invert it\n",
    "                _, binary_image = cv2.threshold(gray_image, 127, 255, cv2.THRESH_BINARY)\n",
    "                binary_image = cv2.bitwise_not(binary_image)\n",
    "\n",
    "                # Get image dimensions\n",
    "                height, width = binary_image.shape\n",
    "\n",
    "                # Define the slant angles for left and right\n",
    "                left_slant_angle = 10  # degrees\n",
    "                right_slant_angle = -10  # degrees\n",
    "\n",
    "                # Center of the image\n",
    "                center = (width // 2, height // 2)\n",
    "\n",
    "                # Compute the rotation matrices\n",
    "                left_rotation_matrix = cv2.getRotationMatrix2D(center, left_slant_angle, 1)\n",
    "                right_rotation_matrix = cv2.getRotationMatrix2D(center, right_slant_angle, 1)\n",
    "\n",
    "                # Apply the slant (rotation) transformations\n",
    "                left_slanted_image = cv2.warpAffine(binary_image, left_rotation_matrix, (width, height), borderMode=cv2.BORDER_CONSTANT, borderValue=(0,))\n",
    "                right_slanted_image = cv2.warpAffine(binary_image, right_rotation_matrix, (width, height), borderMode=cv2.BORDER_CONSTANT, borderValue=(0,))\n",
    "\n",
    "                # Save the original and slanted images\n",
    "                original_output_path = os.path.join(output_subfolder_path, f\"original_{idx}.png\")\n",
    "                left_slanted_output_path = os.path.join(output_subfolder_path, f\"left_slanted_{idx}.png\")\n",
    "                right_slanted_output_path = os.path.join(output_subfolder_path, f\"right_slanted_{idx}.png\")\n",
    "\n",
    "                cv2.imwrite(original_output_path, binary_image)\n",
    "                cv2.imwrite(left_slanted_output_path, left_slanted_image)\n",
    "                cv2.imwrite(right_slanted_output_path, right_slanted_image)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {input_path}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set your input folder and output folder for images\n",
    "    input_folder = 'D:\\\\Tulu_lipi\\\\Output'  # Change this to your input images folder path\n",
    "    output_folder = 'D:\\\\Tulu_lipi\\\\dataset'  # Change this to your output folder for augmented images\n",
    "\n",
    "    # Augment the images with left and right slants, and save the results\n",
    "    augment_images_with_slant(input_folder, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68956367-861d-4cea-95f5-1b4ee6a671fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the mapping from Tulu folder names to Kannada characters\n",
    "tulu_to_kannada_mapping = {\n",
    "    'character_1': 'ಅ',\n",
    "    'character_2': 'ಆ',\n",
    "    'character_3': 'ಇ',\n",
    "    'character_4': 'ಈ',\n",
    "    'character_5': 'ಉ',\n",
    "    'character_6': 'ಊ',\n",
    "    'character_7': 'ಋ',\n",
    "    'character_8': 'ೠ',\n",
    "    'character_9': 'ಎ',\n",
    "    'character_10': 'ಏ',\n",
    "    'character_11': 'ಐ',\n",
    "    'character_12': 'ಒ',\n",
    "    'character_13': 'ಔ',\n",
    "    'character_14': 'ಅಂ',\n",
    "    'character_15': 'ಅಃ',\n",
    "    'character_16': 'ಕ',\n",
    "    'character_17': 'ಖ',\n",
    "    'character_18': 'ಗ',\n",
    "    'character_19': 'ಘ',\n",
    "    'character_20': 'ಙ',\n",
    "    'character_21': 'ಚ',\n",
    "    'character_22': 'ಛ',\n",
    "    'character_23': 'ಜ',\n",
    "    'character_24': 'ಝ',\n",
    "    'character_25': 'ಞ',\n",
    "    'character_26': 'ಟ',\n",
    "    'character_27': 'ಠ',\n",
    "    'character_28': 'ಡ',\n",
    "    'character_29': 'ಢ',\n",
    "    'character_30': 'ಣ',\n",
    "    'character_31': 'ತ',\n",
    "    'character_32': 'ಥ',\n",
    "    'character_33': 'ದ',\n",
    "    'character_34': 'ಧ',\n",
    "    'character_35': 'ನ',\n",
    "    'character_36': 'ಪ',\n",
    "    'character_37': 'ಫ',\n",
    "    'character_38': 'ಬ',\n",
    "    'character_39': 'ಭ',\n",
    "    'character_40': 'ಮ',\n",
    "    'character_41': 'ಯ',\n",
    "    'character_42': 'ರ',\n",
    "    'character_43': 'ಲ',\n",
    "    'character_44': 'ವ',\n",
    "    'character_45': 'ಶ',\n",
    "    'character_46': 'ಷ',\n",
    "    'character_47': 'ಸ',\n",
    "    'character_48': 'ಹ',\n",
    "     'character_49': 'ಳ',\n",
    "    # Add mappings for remaining characters if there are more\n",
    "}\n",
    "\n",
    "# Path to the dataset\n",
    "tulu_characters_folder = \"D:\\\\Tulu_lipi\\\\dataset\"\n",
    "\n",
    "# Rename directories and images based on the mapping\n",
    "def rename_folders_and_images_to_kannada_characters(root_folder):\n",
    "    # Iterate through each folder in the root folder\n",
    "    for folder_name in os.listdir(root_folder):\n",
    "        folder_path = os.path.join(root_folder, folder_name)\n",
    "        if os.path.isdir(folder_path):\n",
    "            # Get the Kannada character corresponding to the Tulu character folder_name\n",
    "            kannada_character = tulu_to_kannada_mapping.get(folder_name, 'Unknown')\n",
    "            \n",
    "            # New folder path\n",
    "            new_folder_path = os.path.join(root_folder, kannada_character)\n",
    "            os.rename(folder_path, new_folder_path)\n",
    "            \n",
    "            # Rename images inside the folder\n",
    "            for idx, image_name in enumerate(os.listdir(new_folder_path)):\n",
    "                image_path = os.path.join(new_folder_path, image_name)\n",
    "                if os.path.isfile(image_path):\n",
    "                    # Create the new image name with a unique identifier\n",
    "                    new_image_name = f\"{kannada_character}_{idx+1}{os.path.splitext(image_name)[1]}\"\n",
    "                    new_image_path = os.path.join(new_folder_path, new_image_name)\n",
    "                    os.rename(image_path, new_image_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Rename the folders and images to Kannada characters based on the mappings\n",
    "    rename_folders_and_images_to_kannada_characters(tulu_characters_folder)\n",
    "    print(\"Folder and image renaming to Kannada characters completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a5bf85-680e-40f2-aa33-9ee93c854b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define image dimensions and paths\n",
    "img_height, img_width = 150, 150\n",
    "batch_size = 32\n",
    "data_dir = 'D:\\\\Tulu_lipi\\\\dataset'\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,  # 20% of data for validation\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d62760-ae6f-4d57-8b36-6a252c4d625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "num_classes=49\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae3583-4e78-4be7-b57e-6d9b8a97d858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(0.25),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(49, activation='softmax')  # 49 classes for 49 characters\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991d5df-d879-4c6b-9d88-75a18b10bd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size,\n",
    "    epochs=epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8917c22-8d50-40e1-b9de-be52e16b1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('tulu_character_recognition_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4e36b0-7f6a-40eb-aab5-227800ef9e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_acc = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
    "print(f\"Validation loss: {val_loss:.4f}, Validation accuracy: {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
